{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c9c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cheetah import Segment, ParticleBeam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import epics\n",
    "import os\n",
    "import numpy as np\n",
    "import pprint\n",
    "import h5py\n",
    "from typing import List, Dict, Any, Callable\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_group_contents(group, exclude_keys=None):\n",
    "    \"\"\"Safely extract datasets from a group, handling scalars and nested groups.\"\"\"\n",
    "    if exclude_keys is None:\n",
    "        exclude_keys = set()\n",
    "    data = {}\n",
    "    for key in group:\n",
    "        if key in exclude_keys:\n",
    "            continue\n",
    "        item = group[key]\n",
    "        if isinstance(item, h5py.Dataset):\n",
    "            data[key] = item[()] if item.shape == () else item[:]\n",
    "        elif isinstance(item, h5py.Group):\n",
    "            data[key] = extract_group_contents(item, exclude_keys)\n",
    "    return data\n",
    "\n",
    "\n",
    "images = {}\n",
    "with h5py.File('../h5/tcav_calibration.h5', 'r') as f:\n",
    "    image_root = f['images']\n",
    "    exclude_keys = {'raw_images','processed_images','total_intensities', 'signal_to_noise_ratios'}\n",
    "\n",
    "    for image_key in image_root:\n",
    "        image_group = image_root[image_key]\n",
    "        image_data = extract_group_contents(image_group, exclude_keys=exclude_keys)\n",
    "        images[image_key] = image_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since all the quad settings are matched in the simulated server and calibration file the only PVs we care about is tcav AREQ, PREQ\n",
    "# Can extract these values from the group contents pretty easily\n",
    "# We will also plot the average beam size x measurement versus phase\n",
    "\n",
    "keys = [key for key in images.keys()]\n",
    "centroid_stack = np.stack([\n",
    "    np.nanmean(images[key]['centroids'],axis=0) for key in keys])\n",
    "phase_stack = np.stack([\n",
    "    images[key]['TCAV:DIAG0:11:PREQ'] for key in images])\n",
    "phase_stack = phase_stack * (math.pi/180)\n",
    "print(phase_stack)\n",
    "print(centroid_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d7592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "X= phase_stack\n",
    "Y= centroid_stack\n",
    "# 1. Linear fit for centroid X\n",
    "def linear(x, m, b):\n",
    "    return m * x + b\n",
    "\n",
    "params_x, _ = curve_fit(linear, X, Y[:, 0])\n",
    "fit_x = linear(X, *params_x)\n",
    "\n",
    "# 2. Sine fit for centroid Y (still using degrees)\n",
    "def sine_deg(x_deg, amplitude, phase_shift, frequency, offset):\n",
    "    x_rad = np.radians(x_deg)\n",
    "    return amplitude * np.sin(frequency * x_rad + phase_shift) + offset\n",
    "\n",
    "p0_y = [np.ptp(Y[:, 1]) / 2, 0.0, 1.0, np.mean(Y[:, 1])]\n",
    "params_y, _ = curve_fit(sine_deg, X, Y[:, 1], p0=p0_y)\n",
    "fit_y = sine_deg(X, *params_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Centroid X (Linear)\n",
    "axes[0].scatter(X, Y[:, 0], color='red', label='Centroid X')\n",
    "axes[0].plot(X, fit_x, color='black', linestyle='--', label='Linear Fit')\n",
    "axes[0].set_title('Centroid X vs Phase (Linear)')\n",
    "axes[0].set_xlabel('Phase [deg]')\n",
    "axes[0].set_ylabel('Centroid X')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "# Suppose params_x = [m, b]\n",
    "eqn_x = f\"y = {params_x[0]:.3f}·x + {params_x[1]:.3f}\"\n",
    "axes[0].text(0.05, 0.95, eqn_x, transform=axes[0].transAxes,\n",
    "             fontsize=12, verticalalignment='bottom', bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "# Centroid Y (Sine)\n",
    "axes[1].scatter(X, Y[:, 1], color='green', label='Centroid Y')\n",
    "axes[1].plot(X, fit_y, color='black', linestyle='--', label='Sine Fit')\n",
    "axes[1].set_title('Centroid Y vs Phase (Sine)')\n",
    "axes[1].set_xlabel('Phase [deg]')\n",
    "axes[1].set_ylabel('Centroid Y')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lcls_tools.common.devices.reader import create_screen, create_tcav, create_magnet\n",
    "from ml_tto.automatic_emittance.screen_profile import ScreenBeamProfileMeasurement\n",
    "from ml_tto.automatic_emittance.image_projection_fit import RecursiveImageProjectionFit\n",
    "from ml_tto.automatic_emittance.plotting import plot_image_projection_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b64ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_side_by_side(img1: np.ndarray, img2: np.ndarray, titles=('Original', 'Noisy'), cmap='hot'):\n",
    "    \"\"\"\n",
    "    Plot two 2D images side-by-side as heat maps.\n",
    "\n",
    "    Parameters:\n",
    "        img1, img2 (np.ndarray): 2D arrays to plot.\n",
    "        titles (tuple): Titles for the subplots.\n",
    "        cmap (str): Colormap to use.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    for ax, img, title in zip(axes, [img1, img2], titles):\n",
    "        im = ax.imshow(img, cmap=cmap, origin='lower', aspect='auto')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('X pixels')\n",
    "        ax.set_ylabel('Y pixels')\n",
    "        fig.colorbar(im, ax=ax, shrink=0.75, label='Intensity')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda34fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start server, track screen, fit beam get result, vary phase repeat for each phase in phase_stack, use lcls_tools library to control\n",
    "# the screen, tcav, and magnets if needed\n",
    "#TODO: fix tcav.phase_set not fucking working\n",
    "screen = create_screen('DIAG0', 'OTRDG02')\n",
    "#tcav = create_tcav('DIAG0', 'TCXDG0')\n",
    "\n",
    "images = []\n",
    "image =  screen.image \n",
    "noise_std = 0.2 * np.max(image)\n",
    "image_noisey = image + np.abs(np.random.normal(loc=0, scale=noise_std, size=image.shape))\n",
    "show_side_by_side(image,image_noisey)\n",
    "\n",
    "i= 0\n",
    "for phase in phase_stack:\n",
    "    epics.caput('TCAV:DIAG0:11:PREQ', phase)\n",
    "    image =  screen.image\n",
    "    noise_std = 0.2 * (np.max(image) + .0001)\n",
    "    #image += np.abs(np.random.normal(loc=0, scale= noise_std , size=image.shape))\n",
    "    if i ==0:\n",
    "        sneaky = image\n",
    "    i+=1\n",
    "    images.append(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit images get centroids\n",
    "#bad fits... eed to get centroids some other way\n",
    "recImg = RecursiveImageProjectionFit(visualize=False)\n",
    "sim_centroids = []\n",
    "for image in images:\n",
    "    result = recImg._fit_image(image)\n",
    "    sim_centroids.append(result.centroid)\n",
    "    #Dump images to file for training set.\n",
    "\n",
    "sim_centroids_stack = np.stack([centroid for centroid in sim_centroids])\n",
    "#plt.imshow(sneaky, cmap='hot', origin='lower', aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d63250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: figure out what the problem with the fits is? for now interpolate points and try and optimize with a few interpolated points\n",
    "c = torch.tensor(sim_centroids)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b96ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def interpolate_nans(data):\n",
    "    \"\"\"\n",
    "    Linearly interpolates missing values (np.nan) in a 1D NumPy array or PyTorch tensor.\n",
    "    Extrapolates linearly at the ends if NaNs are present there.\n",
    "    \n",
    "    Parameters:\n",
    "        data (np.ndarray or torch.Tensor): 1D array/tensor with NaNs.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 1D tensor with NaNs filled.\n",
    "    \"\"\"\n",
    "    # Convert to NumPy array if torch tensor\n",
    "    is_tensor = isinstance(data, torch.Tensor)\n",
    "    arr = data.numpy() if is_tensor else np.array(data, dtype=float)\n",
    "\n",
    "    x = np.arange(len(arr))\n",
    "    mask = np.isnan(arr)\n",
    "\n",
    "    if np.all(mask):\n",
    "        raise ValueError(\"All values are NaN — cannot interpolate.\")\n",
    "\n",
    "    known_x = x[~mask]\n",
    "    known_y = arr[~mask]\n",
    "\n",
    "    # Interpolate internal NaNs\n",
    "    arr[mask] = np.interp(x[mask], known_x, known_y)\n",
    "\n",
    "    # Extrapolate leading NaNs\n",
    "    if known_x[0] > 0:\n",
    "        slope_start = (known_y[1] - known_y[0]) / (known_x[1] - known_x[0])\n",
    "        for i in range(known_x[0]):\n",
    "            arr[i] = known_y[0] - (known_x[0] - i) * slope_start\n",
    "\n",
    "    # Extrapolate trailing NaNs\n",
    "    if known_x[-1] < len(arr) - 1:\n",
    "        slope_end = (known_y[-1] - known_y[-2]) / (known_x[-1] - known_x[-2])\n",
    "        for i in range(known_x[-1] + 1, len(arr)):\n",
    "            arr[i] = known_y[-1] + (i - known_x[-1]) * slope_end\n",
    "\n",
    "    return torch.tensor(arr) if is_tensor else arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In all the times i ran the program this was the best set of fits so I felt liek it was worth keeping and interoplating\n",
    "best_fits= torch.tensor([np.nan, 802.31841187, 758.54816323, 716.24749925,\n",
    "       685.01428837, 653.7810775 , 625.62393425, 598.56945705,\n",
    "       np.nan, np.nan])\n",
    "interpolated = interpolate_nans(best_fits)\n",
    "interpolated2 = interpolate_nans(c[:,0])\n",
    "\n",
    "print(interpolated)\n",
    "print(interpolated2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f091d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find fit of sim data\n",
    "params_x_sim, _ = curve_fit(linear, X, interpolated2)\n",
    "fit_x_sim = linear(X, *params_x_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f072fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axes = plt.subplots( figsize=(12, 4))\n",
    "\n",
    "# Centroid X (Linear)\n",
    "axes.scatter(X, Y[:, 0], color='red', label='Centroid X')\n",
    "axes.scatter(X,interpolated2, color= 'green', label = 'Centroid X Sim')\n",
    "axes.plot(X, fit_x, color='black', linestyle='--', label='Experiment Fit')\n",
    "axes.plot(X, fit_x_sim, color='blue', linestyle='--', label='Sim Fit')\n",
    "axes.set_title('Centroid X vs Phase (Linear)')\n",
    "axes.set_xlabel('Phase [deg]')\n",
    "axes.set_ylabel('Centroid X')\n",
    "axes.legend()\n",
    "axes.grid(True)\n",
    "# Suppose params_x = [m, b]\n",
    "eqn_x = f\"y = {params_x[0]:.3f}·x + {params_x[1]:.3f}\"\n",
    "axes.text(0.05, 0.95, eqn_x, transform=axes.transAxes,\n",
    "             fontsize=12, verticalalignment='bottom', bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa930ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "voltage_in_MV = epics.caget('TCAV:DIAG0:11:AREQ', use_monitor=False)\n",
    "print(f'before {voltage_in_MV}')\n",
    "voltage_in_MV = voltage_in_MV + .01\n",
    "epics.caput('TCAV:DIAG0:11:AREQ', voltage_in_MV)\n",
    "voltage_in_MV = epics.caget('TCAV:DIAG0:11:AREQ', use_monitor=False)\n",
    "print(f'after {voltage_in_MV}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228dc85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how is the amplitude related to the slope of the curve? \n",
    "def train(num_steps:int, target_beam_parameters: epics.PV, lr = .0001) -> dict:\n",
    "    # working in single case for now.\n",
    "    beam_parameter_history = []\n",
    "    loss_history = []\n",
    "    amplitude = epics.caget('TCAV:DIAG0:11:AREQ', use_monitor=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ad3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "recImg = RecursiveImageProjectionFit(visualize=False)\n",
    "screen = create_screen('DIAG0', 'OTRDG02')\n",
    "tcav = create_tcav('DIAG0','TCXDG0')\n",
    "tcav.amp_set = 0.0\n",
    "#TODO: submit lclstools pr tcav. \n",
    "centroid_zerod = screen.image\n",
    "result = recImg.fit_image(centroid_zerod)\n",
    "zero_point = result.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ac3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcav.amp_set = .135\n",
    "print(f'This is the {tcav.phase_set}')\n",
    "centroid_nominal = screen.image\n",
    "result_nom = recImg.fit_image(centroid_nominal)\n",
    "nominal_point = result_nom.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55180ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"nominal {nominal_point}\")\n",
    "print(f\"zero'd {zero_point}\")\n",
    "cent_x = zero_point[0]\n",
    "\n",
    "#nominal [np.float64(1004.7178445383822), np.float64(736.4506846286199)]\n",
    "#zero'd [np.float64(971.9258468438095), np.float64(736.448910940515)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de1dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt.vocs import VOCS\n",
    "from xopt.evaluator import Evaluator\n",
    "from xopt.generators.bayesian import UpperConfidenceBoundGenerator\n",
    "from xopt import Xopt\n",
    "\n",
    "vocs = VOCS(\n",
    "    variables={\"phase\": [-180, 180]},\n",
    "    objectives={\"f\": \"MINIMIZE\"},\n",
    ")\n",
    "# want minimize the distance between zero_point value created by phase\n",
    "def phase_scan(input_dict):\n",
    "    tcav.phase_set = input_dict[\"phase\"]\n",
    "    print(tcav.phase_set)\n",
    "    image = screen.image\n",
    "    result = recImg.fit_image(image)\n",
    "    cent_x_scan = result.centroid[0]\n",
    "    value = (cent_x - cent_x_scan)**2\n",
    "    return {\"f\": value}\n",
    "# Take sqrt of value\n",
    "evaluator = Evaluator(function=phase_scan)\n",
    "generator = UpperConfidenceBoundGenerator(vocs=vocs)\n",
    "generator.gp_constructor.use_low_noise_prior = True\n",
    "X = Xopt(evaluator=evaluator, generator=generator, vocs=vocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ceae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call X.random_evaluate() to generate + evaluate 3 initial points\n",
    "#X.random_evaluate(2)\n",
    "X.evaluate_data({'phase':np.linspace(-180,180,10)})\n",
    "# inspect the gathered data\n",
    "X.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d84f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 5\n",
    "\n",
    "# test points for plotting\n",
    "test_x = torch.linspace(*X.vocs.bounds.flatten(), 50).double()\n",
    "\n",
    "for i in range(n_steps):\n",
    "    # get the Gaussian process model from the generator\n",
    "    model = X.generator.train_model()\n",
    "\n",
    "    # get acquisition function from generator\n",
    "    acq = X.generator.get_acquisition(model)\n",
    "\n",
    "    # calculate model posterior and acquisition function at each test point\n",
    "    # NOTE: need to add a dimension to the input tensor for evaluating the\n",
    "    # posterior and another for the acquisition function, see\n",
    "    # https://botorch.org/docs/batching for details\n",
    "    # NOTE: we use the `torch.no_grad()` environment to speed up computation by\n",
    "    # skipping calculations for backpropagation\n",
    "    with torch.no_grad():\n",
    "        posterior = model.posterior(test_x.unsqueeze(1))\n",
    "        acq_val = acq(test_x.reshape(-1, 1, 1))\n",
    "\n",
    "    # get mean function and confidence regions\n",
    "    mean = posterior.mean\n",
    "    L, u = posterior.mvn.confidence_region()\n",
    "\n",
    "    # plot model and acquisition function\n",
    "    fig, ax = plt.subplots(2, 1, sharex=\"all\")\n",
    "\n",
    "    # plot model posterior\n",
    "    ax[0].plot(test_x, mean, label=\"Posterior mean\")\n",
    "    ax[0].fill_between(test_x, L, u, alpha=0.25, label=\"Posterior confidence region\")\n",
    "\n",
    "    # add data to model plot\n",
    "    ax[0].plot(X.data[\"phase\"], X.data[\"f\"], \"C1o\", label=\"Training data\")\n",
    "\n",
    "    '''\n",
    "    # plot true function\n",
    "    true_f = sin_function({\"x\": test_x})[\"f\"]\n",
    "    ax[0].plot(test_x, true_f, \"--\", label=\"Ground truth\")\n",
    "    '''\n",
    "    # add legend\n",
    "    ax[0].legend()\n",
    "\n",
    "    # plot acquisition function\n",
    "    ax[1].plot(test_x, acq_val.flatten())\n",
    "\n",
    "    ax[0].set_ylabel(\"f\")\n",
    "    ax[1].set_ylabel(r\"$\\alpha(x)$\")\n",
    "    ax[1].set_xlabel(\"x\")\n",
    "\n",
    "    # do the optimization step\n",
    "    X.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa045522",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f2de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.data.scatter(x='phase', y ='f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d507800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linac-simulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
